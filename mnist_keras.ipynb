{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whiteBerryJ/Keras_MNIST_Maixpy/blob/main/mnist_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8HQTxoHRaGO"
      },
      "source": [
        "번역 및 수정 스크립트 <br>\n",
        "https://github.com/ashitani/jupyter_examples/blob/master/mnist_keras_maixpy_colab.ipynb\n",
        "\n",
        "# Keras / MNIST / Maixpy\n",
        "\n",
        "Keras에서 MNIST 모델을 학습하고 Maixpy에 배치 될 때까지를 설명합니다.\n",
        "\n",
        "# 환경 구축\n",
        "\n",
        "- Maix_Toolbox는 편리한 도구 세트입니다.\n",
        "- 거기에서 참조되는 ncc (TensorflowLite 출력 K210의 KPU에서 실행할 수 kmodel 형식으로 변환하는 도구)를 설치. Linux 용 바이너리를 제공하고, Google Colab에서 직접 실행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm5RqgUfRi-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcff9c54-99c6-43ca-a005-e653330d8df8"
      },
      "source": [
        "!git clone https://github.com/sipeed/Maix_Toolbox\n",
        "!mkdir Maix_Toolbox/workspace\n",
        "!mkdir Maix_Toolbox/ncc\n",
        "%cd /content/Maix_Toolbox/ncc\n",
        "!wget https://github.com/kendryte/nncase/releases/download/v0.1.0-rc5/ncc-linux-x86_64.tar.xz\n",
        "!tar Jxf ncc-linux-x86_64.tar.xz\n",
        "%cd /content/Maix_Toolbox/workspace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Maix_Toolbox'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Total 34 (delta 0), reused 0 (delta 0), pack-reused 34\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n",
            "/content/Maix_Toolbox/ncc\n",
            "--2021-08-13 05:45:27--  https://github.com/kendryte/nncase/releases/download/v0.1.0-rc5/ncc-linux-x86_64.tar.xz\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/128056991/86526300-8233-11e9-91ac-884e08be60de?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210813%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210813T054527Z&X-Amz-Expires=300&X-Amz-Signature=bcc37bb03eabd8659009e578734015c58e293e84e3bc6fa2f1bc80b15cbb4ca5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=128056991&response-content-disposition=attachment%3B%20filename%3Dncc-linux-x86_64.tar.xz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-08-13 05:45:27--  https://github-releases.githubusercontent.com/128056991/86526300-8233-11e9-91ac-884e08be60de?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210813%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210813T054527Z&X-Amz-Expires=300&X-Amz-Signature=bcc37bb03eabd8659009e578734015c58e293e84e3bc6fa2f1bc80b15cbb4ca5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=128056991&response-content-disposition=attachment%3B%20filename%3Dncc-linux-x86_64.tar.xz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 54220128 (52M) [application/octet-stream]\n",
            "Saving to: ‘ncc-linux-x86_64.tar.xz’\n",
            "\n",
            "ncc-linux-x86_64.ta 100%[===================>]  51.71M  39.5MB/s    in 1.3s    \n",
            "\n",
            "2021-08-13 05:45:29 (39.5 MB/s) - ‘ncc-linux-x86_64.tar.xz’ saved [54220128/54220128]\n",
            "\n",
            "/content/Maix_Toolbox/workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFuX6zmHRkpH"
      },
      "source": [
        "# 학습\n",
        "\n",
        "[keras의 mnist_cnn (https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)을 일부 수정했습니다.\n",
        "\n",
        "- Conv2D는 padding = \"same\"아니면 nnc로 변환 할 수 없기 때문에 옵션을 추기했습니다.\n",
        "- 아래의 모델에서 Dense 매개 변수 크기가 너무 커서 메모리가 초과되기 때문에 전단에 MaxPool을 적용시키거나 Dense 층의 차원을 128-> 32로 감소시켰습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ7k4fwQSY4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0512f1-5de7-48f6-8f6d-3e1b8fdfe993"
      },
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 1\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(type(x_train[0][0][0]))\n",
        "print(type(y_train[0]), y_train.shape)\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(type(y_train[0][0]), y_train.shape)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 padding='same', # nncase supports only padding==same\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # added because model size is too large\n",
        "model.add(Conv2D(32, (3, 3), \n",
        "                 padding='same', # nncase supports only padding==same\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu')) # modified because model size is too large\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.save(\"/content/Maix_Toolbox/workspace/mnist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "<class 'numpy.uint8'>\n",
            "<class 'numpy.uint8'> (60000,)\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "<class 'numpy.float32'> (60000, 10)\n",
            "469/469 [==============================] - 48s 7ms/step - loss: 2.3081 - accuracy: 0.1062 - val_loss: 2.2942 - val_accuracy: 0.1543\n",
            "Test loss: 2.2941689491271973\n",
            "Test accuracy: 0.1543000042438507\n",
            "INFO:tensorflow:Assets written to: /content/Maix_Toolbox/workspace/mnist/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkjlZPH5KbY_"
      },
      "source": [
        "### Get dummy data to test on board"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsKWVbYSFoXT",
        "outputId": "c11b6394-9220-4438-b75d-24cce94b67d4"
      },
      "source": [
        "# array = x_train[10].reshape(1,28,28)[0]\n",
        "# array = array * 2147483647\n",
        "# array = array.astype('int32')\n",
        "# print(type(array[0][0]))\n",
        "# print('[', end='')\n",
        "# for i in range(len(array)):\n",
        "# \tprint('[', end='')\n",
        "# \tfor j in range(len(array[0])):\n",
        "# \t\tprint(array[i][j], end='')\n",
        "# \t\tif j == 149:\n",
        "# \t\t\tbreak\n",
        "# \t\tprint(', ', end='')\n",
        "# \tif i == 9:\n",
        "# \t\tprint(']', end='')\n",
        "# \telse:\n",
        "# \t\tprint('],')\n",
        "# print(']')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int32'>\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 353703199, 993737535, 1844309503, 1397969791, 993737535, 993737535, 50529027, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 867414975, 2038004095, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 555819327, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 151587087, 1953789055, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 2004318079, 589505343, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 875836479, 2054847103, 2139062143, 1886417023, 2139062143, 2139062143, 2139062143, 1187432191, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1743251455, 2139062143, 1768515967, 2139062143, 2139062143, 2139062143, 286331167, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 707406399, 1734829951, 2139062143, 2139062143, 2139062143, 2139062143, 345281695, 0, 0, 0, 0, 0, 0, 0, 0, 0, ][0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 202116111, 1760094463, 2139062143, 2139062143, 2139062143, 1440077311, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 766356927, 1153746175, 2130640639, 2139062143, 2139062143, 2139062143, 943208511, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 336860191, 1802201983, 2105376127, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 286331167, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 682141887, 2080111615, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 1229539711, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 926365503, 2071690111, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 1440077311, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 614769855, 749513919, 749513919, 783199935, 2021161087, 2139062143, 1440077311, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8421504, 1077952639, 2139062143, 1844309503, 261066639, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58950531, 2139062143, 2139062143, 1802201983, 235802127, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1162167679, 2139062143, 2139062143, 976894527, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 160008591, 1490606335, 757935423, 0, 0, 0, 0, 0, 210537615, 2021161087, 2139062143, 2139062143, 286331167, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 1381126783, 2139062143, 1810623487, 530554783, 303174175, 0, 429496735, 749513919, 1734829951, 2139062143, 2139062143, 1170589183, 67372039, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 480025759, 1659036415, 2139062143, 2139062143, 1869574015, 1515870847, 2029582591, 2139062143, 2139062143, 2130640639, 1793780479, 92636551, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 1179010687, 884257983, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 2139062143, 1987475071, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 58950531, 985316031, 985316031, 1389548287, 2139062143, 2139062143, 2012739583, 421075231, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4A0tqqCSjTd"
      },
      "source": [
        "# 모델 변환\n",
        "\n",
        "- 사전 준비\n",
        "    - kmodel로 변환 할 때 테스트 이미지가 images 폴더에 없으면 변환할 수  없습니다. (이것을 사용하여 양자화시의 다이내믹 레인지 추정하는 것) 따라서 테스트 이미지를 생성합니다. 결국 저장할 때 uint8이기 때문에 uint8로 변환하지 않으면 안됩니다.\n",
        "    - flash-list.json를 준비 (여기 (http://blog.sipeed.com/p/390.html) 가 추가됩니다)\n",
        "- tflite_convert에서 h5-> TensorflowLite로 변환합니다.\n",
        "- tflite2kmodel.sh에서 kmodel로 변환합니다.\n",
        "- [여기] (https://github.com/sipeed/LicheeDan_K210_examples/tree/master/src/mnist) 를 참고하여 kmodel를 flash-list.json 함께 tar하여 kpkg 파일을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x7DqCiHTh2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311e3f1a-fd0b-4630-b355-9c002b0491a0"
      },
      "source": [
        "%cd /content/Maix_Toolbox/\n",
        "!mkdir images\n",
        "import numpy as np\n",
        "import cv2\n",
        "batch_num=100\n",
        "batch = x_train[0:batch_num]\n",
        "imgs=batch.reshape((batch_num,28,28))*255\n",
        "imgs=imgs.astype(np.uint8)\n",
        "for i,img in enumerate(imgs):\n",
        "  cv2.imwrite(\"images/%03d.jpg\"%i, img)\n",
        "\n",
        "jsontext=\"\"\"\n",
        "{\n",
        "  \"version\": \"0.1.0\",\n",
        "  \"files\": [\n",
        "    {\n",
        "      \"address\": 0x00300000,\n",
        "      \"bin\": \"mnist.kmodel\",\n",
        "      \"sha256Prefix\": false\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"workspace/flash-list.json\",\"w\") as f:\n",
        "  f.write(jsontext)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Maix_Toolbox\n",
            "mkdir: cannot create directory ‘images’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjyXcmRBOrgR"
      },
      "source": [
        "## Convert\n",
        "warning : KPU support only 3x3 kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYBBTyIxSYb",
        "outputId": "544add6d-4fc7-4440-fea7-46b0340ec6fb"
      },
      "source": [
        "%cd /content/Maix_Toolbox/\n",
        "!tflite_convert  --output_file=/content/Maix_Toolbox/workspace/mnist.tflite --saved_model_dir=/content/Maix_Toolbox/workspace/mnist\n",
        "!./tflite2kmodel.sh workspace/mnist.tflite\n",
        "!./ncc/ncc -i tflite -o k210model --dataset /content/Maix_Toolbox/images /content/Maix_Toolbox/workspace/mnist.tflite /content/Maix_Toolbox/workspace/mnist.kmodel\n",
        "%cd /content/Maix_Toolbox/workspace\n",
        "!zip -r mnist_at_0x300000.kfpkg mnist.kmodel flash-list.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Maix_Toolbox\n",
            "2021-08-11 04:00:41.300792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-11 04:00:41.306180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.306780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-11 04:00:41.307035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-11 04:00:41.308610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-11 04:00:41.310540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-11 04:00:41.310854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-11 04:00:41.312543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-11 04:00:41.313553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-11 04:00:41.317224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-11 04:00:41.317332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.317880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.318370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-08-11 04:00:41.318581: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-08-11 04:00:41.323513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2021-08-11 04:00:41.323710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562b6d2ad2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-11 04:00:41.323736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-08-11 04:00:41.414329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.415022: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562b6d2ad480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-11 04:00:41.415056: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-08-11 04:00:41.415226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.415752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-11 04:00:41.415807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-11 04:00:41.415831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-11 04:00:41.415850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-11 04:00:41.415871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-11 04:00:41.415889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-11 04:00:41.415906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-11 04:00:41.415923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-11 04:00:41.415987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.416536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.417015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-08-11 04:00:41.417069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-11 04:00:41.418061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-11 04:00:41.418089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-08-11 04:00:41.418100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-08-11 04:00:41.418211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.418748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:41.419253: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-11 04:00:41.419297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13270 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-08-11 04:00:42.195656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.196296: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-08-11 04:00:42.196395: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-08-11 04:00:42.197037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.197716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-11 04:00:42.197780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-11 04:00:42.197804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-11 04:00:42.197826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-11 04:00:42.197848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-11 04:00:42.197869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-11 04:00:42.197888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-11 04:00:42.197909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-11 04:00:42.197975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.198610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.199149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-08-11 04:00:42.199190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-11 04:00:42.199204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-08-11 04:00:42.199219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-08-11 04:00:42.199326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.199924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.200527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13270 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-08-11 04:00:42.202966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\n",
            "2021-08-11 04:00:42.203000: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 49 nodes (38), 82 edges (71), time = 1.117ms.\n",
            "2021-08-11 04:00:42.203012: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.017ms.\n",
            "2021-08-11 04:00:42.249732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.250278: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-08-11 04:00:42.250358: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-08-11 04:00:42.250829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.251366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-08-11 04:00:42.251427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-11 04:00:42.251449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-11 04:00:42.251471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-11 04:00:42.251489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-11 04:00:42.251506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-11 04:00:42.251524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-11 04:00:42.251544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-11 04:00:42.251601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.252119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.252616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-08-11 04:00:42.252652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-11 04:00:42.252664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-08-11 04:00:42.252677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-08-11 04:00:42.252757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.253301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-11 04:00:42.253799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13270 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-08-11 04:00:42.264785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\n",
            "2021-08-11 04:00:42.264812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 41 nodes (-8), 66 edges (-16), time = 7.203ms.\n",
            "2021-08-11 04:00:42.264822: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 41 nodes (0), 66 edges (0), time = 1.532ms.\n",
            "uasge: ./tflite2kmodel.sh xxx.tflite\n",
            "2021-08-11 04:00:45.028578: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "Fatal: Layer Conv2d is not supported\n",
            "NnCase.Converter.Converters.LayerNotSupportedException: Layer Conv2d is not supported\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.Convert(Graph graph, QuantizationContext quantizationContext, Int32 weightsBits) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 60\n",
            "   at NnCase.Converter.K210.Converters.GraphToK210Converter.ConvertAsync(Dataset dataset, GraphPlanContext planContext, String outputDir, String prefix, Boolean channelwiseOutput) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\GraphToK210Converter.cs:line 40\n",
            "   at NnCase.Cli.Program.Main(String[] args) in D:\\Work\\Repository\\nncase\\src\\NnCase.Cli\\Program.cs:line 271\n",
            "   at NnCase.Cli.Program.<Main>(String[] args)\n",
            "2021-08-11 04:00:46.196684: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "Fatal: Layer Conv2d is not supported\n",
            "NnCase.Converter.Converters.LayerNotSupportedException: Layer Conv2d is not supported\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.<Convert>g__ConvertLayer|0_6(Layer layer, <>c__DisplayClass0_0& ) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 51\n",
            "   at NnCase.Converter.K210.Converters.Stages.Convert.Converter.Convert(Graph graph, QuantizationContext quantizationContext, Int32 weightsBits) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\Stages\\Convert\\Converter.cs:line 60\n",
            "   at NnCase.Converter.K210.Converters.GraphToK210Converter.ConvertAsync(Dataset dataset, GraphPlanContext planContext, String outputDir, String prefix, Boolean channelwiseOutput) in D:\\Work\\Repository\\nncase\\src\\NnCase.Converter.K210\\Converters\\GraphToK210Converter.cs:line 40\n",
            "   at NnCase.Cli.Program.Main(String[] args) in D:\\Work\\Repository\\nncase\\src\\NnCase.Cli\\Program.cs:line 271\n",
            "   at NnCase.Cli.Program.<Main>(String[] args)\n",
            "/content/Maix_Toolbox/workspace\n",
            "updating: flash-list.json (deflated 24%)\n",
            "updating: mnist.kmodel (deflated 9%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HEykstOTxo2"
      },
      "source": [
        "# 장치에 전송 및 실행\n",
        "\n",
        "mnist_at_0x300000.kfpkg을 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WksRhutIf7bP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "aa0c1f4f-1936-4c39-f5e1-123f4b2e3e7c"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('mnist_at_0x300000.kfpkg')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_513ce7d7-12f3-4be9-8086-359abfe67837\", \"mnist_at_0x300000.kfpkg\", 392614)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaEb8UZ6UPFq"
      },
      "source": [
        "kflash.py에 굽는 경우\n",
        "\n",
        "```\n",
        "python3 kflash.py -p / dev / *** mnist.kfpkg\n",
        "```\n",
        "\n",
        "등등의 Ok입니다. 물론 kflash_gui를 사용해도 좋습니다.\n",
        "\n",
        "농장은이 정도 크기의 모델이면 기본 (maixpy_v0.3.2_full.bin)의 Ok했지만 큰 모델을 사용하고 싶다면 그만큼 작은 농장을 사용하면 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRbmIhtfUamw"
      },
      "source": [
        "maixpy에 연결 한 다음 Ctrl-E를 입력합니다. 아래 코피 페하고 Ctrl-D로 시작합니다.\n",
        "vflip / hmirror의 둘레는 환경에 맞게 수정하면 좋다고 생각합니다. 자신의 환경 (아키즈키에서 산 Maix Bit Suit)는 vflip이 필요했습니다.\n",
        "\n",
        "\n",
        "```\n",
        "import sensor,lcd,image\n",
        "import KPU as kpu\n",
        "lcd.init()\n",
        "sensor.reset()\n",
        "sensor.set_auto_gain(0,24) # auto gain disable and 24dB\n",
        "sensor.set_pixformat(sensor.RGB565)\n",
        "sensor.set_framesize(sensor.QVGA)\n",
        "sensor.set_windowing((224, 224))    #set to 224x224 input\n",
        "sensor.set_vflip(True)                    #flip camera\n",
        "#sensor.set_hmirror(0)               #flip camera\n",
        "task = kpu.load(0x300000)           #load model from flash address 0x300000\n",
        "sensor.run(1)\n",
        "while True:\n",
        "    img = sensor.snapshot()\n",
        "    lcd.display(img,oft=(0,0))      #display large picture\n",
        "    img1=img.to_grayscale(1)        #convert to gray\n",
        "    img2=img1.resize(28,28)         #resize to mnist input 28x28\n",
        "    a=img2.invert()                 #invert picture as mnist need\n",
        "    a=img2.strech_char(1)           #preprocessing pictures, eliminate dark corner\n",
        "    lcd.display(img2,oft=(224,32))  #display small 28x28 picture\n",
        "    a=img2.pix_to_ai();             #generate data for ai\n",
        "    fmap=kpu.forward(task,img2)     #run neural network model \n",
        "    plist=fmap[:]                   #get result (10 digit's probability)\n",
        "    pmax=max(plist)                 #get max probability\n",
        "    print(plist)\n",
        "    max_index=plist.index(pmax)     #get the digit\n",
        "    lcd.draw_string(224,0,\"%d: %.3f\"%(max_index,pmax),lcd.WHITE,lcd.BLACK)  #show result\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-1Rpu403T2W",
        "outputId": "cb56d83e-d1fe-4de3-c2ed-b24bc6773e83"
      },
      "source": [
        "np.max(x_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMRnMf4E3w7T",
        "outputId": "9b932612-831a-47d1-a1bd-666b1b45d9be"
      },
      "source": [
        "np.min(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlHrWp2M4EtU",
        "outputId": "1059596a-4e47-4641-ac02-3b8517a9e389"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}